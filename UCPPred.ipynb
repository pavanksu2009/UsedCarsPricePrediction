{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train_src_dir and test_src_dir directories to store train and test data respectively \n",
    "train_src_dir = '../UsedCarsPricePrediction/train'\n",
    "test_src_dir = '../UsedCarsPricePrediction/test'\n",
    "# create train and test directories if they don't exist already \n",
    "if not os.path.exists(train_src_dir):\n",
    "    os.mkdir(train_src_dir)\n",
    "    os.mkdir(test_src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../UsedCarsPricePrediction/train/pre_process1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {train_src_dir}/pre_process1.py\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# input_data_path for used_cars.csv from local machine \n",
    "input_data_path = '../UsedCarsPricePrediction/train/used_cars.csv'\n",
    "used_cars = pd.read_csv(input_data_path)\n",
    "\n",
    "target = 'price'\n",
    "numeric_features = ['Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "categorical_features = ['Segment']\n",
    "\n",
    "# X for used_cars.csv from local machine \n",
    "X = used_cars.drop(columns=[target])\n",
    "y = used_cars[target]\n",
    "\n",
    "# split the data into train and test sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=42)\n",
    "\n",
    "# split the train data into train and validation sets\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain,\n",
    "                                              test_size=0.2,\n",
    "                                              random_state=42)\n",
    "\n",
    "# create a preprocessor object to preprocess the data\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore', \n",
    "                   sparse=False), categorical_features)\n",
    ")\n",
    "\n",
    "transformed_Xtrain = preprocessor.fit_transform(Xtrain)\n",
    "transformed_Xval = preprocessor.transform(Xval)\n",
    "transformed_Xtest = preprocessor.transform(Xtest)\n",
    "\n",
    "# train_features_output_path for used_cars.csv from local machine\n",
    "train_features_output_path = os.path.join(\"../UsedCarsPricePrediction/train\", \"train_features.csv\")\n",
    "# train_labels_output_path for used_cars.csv from local machine\n",
    "train_labels_output_path = os.path.join(\"../UsedCarsPricePrediction/train\", \"train_labels.csv\")\n",
    "\n",
    "# validation set for used_cars.csv from local machine\n",
    "val_features_output_path = os.path.join(\"../UsedCarsPricePrediction/train\", \"val_features.csv\")\n",
    "val_labels_output_path = os.path.join(\"../UsedCarsPricePrediction/train\", \"val_labels.csv\")\n",
    "\n",
    "# test_features_output_path for used_cars.csv from local machine\n",
    "test_features_output_path = os.path.join(\"../UsedCarsPricePrediction/test\", \"test_features.csv\")\n",
    "# test_labels_output_path for used_cars.csv from local machine\n",
    "test_labels_output_path = os.path.join(\"../UsedCarsPricePrediction/test\", \"test_labels.csv\")\n",
    "\n",
    "# save the validation set to csv file \n",
    "pd.DataFrame(transformed_Xval).to_csv(val_features_output_path, \n",
    "                                       header=False, index=False)\n",
    "pd.DataFrame(transformed_Xtrain).to_csv(train_features_output_path, \n",
    "                                        header=False, index=False)\n",
    "pd.DataFrame(transformed_Xtest).to_csv(test_features_output_path, \n",
    "                                       header=False, index=False)\n",
    "\n",
    "ytrain.to_csv(train_labels_output_path, header=False, index=False)\n",
    "yval.to_csv(val_labels_output_path, header=False, index=False)\n",
    "ytest.to_csv(test_labels_output_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22.568580326833807;\n",
      "Training Accuracy: 1.0\n",
      "Validation Accuracy: 0.6794940687265967\n",
      "Saving model to ../UsedCarsPricePrediction/model\\model.joblib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../UsedCarsPricePrediction/model\\\\model.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%writefile {train_src_dir}/model_dtr.py\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "\n",
    "# training_data_directory for used_cars.csv from local machine\n",
    "training_data_directory = \"../UsedCarsPricePrediction/train\"\n",
    "# validation_data_directory for used_cars.csv from local machine\n",
    "validation_data_directory = \"../UsedCarsPricePrediction/train\"\n",
    "# test_data_directory for used_cars.csv from local machine\n",
    "test_data_directory = \"../UsedCarsPricePrediction/test\"\n",
    "\n",
    "train_features_data = os.path.join(training_data_directory, \"train_features.csv\") # this \n",
    "train_labels_data = os.path.join(training_data_directory, \"train_labels.csv\")\n",
    "\n",
    "val_features_data = os.path.join(validation_data_directory, \"val_features.csv\")\n",
    "val_labels_data = os.path.join(validation_data_directory, \"val_labels.csv\")\n",
    "\n",
    "test_features_data = os.path.join(test_data_directory, \"test_features.csv\")\n",
    "test_labels_data = os.path.join(test_data_directory, \"test_labels.csv\")\n",
    "\n",
    "X_train = pd.read_csv(train_features_data, header=None)\n",
    "y_train = pd.read_csv(train_labels_data, header=None)\n",
    "\n",
    "model_dt = DecisionTreeRegressor()\n",
    "\n",
    "model_dt.fit(X_train, y_train)\n",
    "\n",
    "# X_test = pd.read_csv(test_features_data, header=None)\n",
    "X_val = pd.read_csv(val_features_data, header=None)\n",
    "y_val = pd.read_csv(val_labels_data, header=None)\n",
    "\n",
    "y_pred_val = model_dt.predict(X_val)\n",
    "\n",
    "# print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False)};\")\n",
    "print(f\"RMSE: {mean_squared_error(y_val, y_pred_val, squared=False)};\")\n",
    "# print accuracy score on the training and validation sets \n",
    "print(f\"Training Accuracy: {model_dt.score(X_train, y_train)}\")\n",
    "print(f\"Validation Accuracy: {model_dt.score(X_val, y_val)}\")\n",
    "\n",
    "# model_output_directory for used_cars.csv from local machine\n",
    "model_output_directory = os.path.join(\"../UsedCarsPricePrediction/model\", \"model.joblib\")\n",
    "\n",
    "print(f\"Saving model to {model_output_directory}\")\n",
    "joblib.dump(model_dt, model_output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test input data\n",
      "RMSE: 8.688475017228281;\n"
     ]
    }
   ],
   "source": [
    "# %%writefile {train_src_dir}/evaluation_dtr.py\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import tarfile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# model_path for used_cars.csv from local machine\n",
    "model_path = f\"../UsedCarsPricePrediction/model/model.joblib\"\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "print(\"Loading test input data\")\n",
    "# test_data_directory for used_cars.csv from local machine\n",
    "test_data_directory = \"../UsedCarsPricePrediction/test\"\n",
    "test_features_data = os.path.join(test_data_directory, \"test_features.csv\")\n",
    "test_labels_data = os.path.join(test_data_directory, \"test_labels.csv\")\n",
    "\n",
    "X_test = pd.read_csv(test_features_data, header=None)\n",
    "y_test = pd.read_csv(test_labels_data, header=None)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False)};\")\n",
    "\n",
    "report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "                \"mse\": {\n",
    "                        \"value\": mean_squared_error(y_test, y_pred)\n",
    "                },\n",
    "                \"rmse\": {\n",
    "                        \"value\": mean_squared_error(y_test, y_pred, squared=False)\n",
    "                },\n",
    "                \"r2\": {\n",
    "                        \"value\": r2_score(y_test, y_pred)\n",
    "                }\n",
    "        }\n",
    "}\n",
    "\n",
    "# evaluation_output_path for used_cars.csv from local machine\n",
    "evaluation_output_path = os.path.join(\"../UsedCarsPricePrediction/evaluation\", \"evaluation.json\")\n",
    "\n",
    "with open(evaluation_output_path, \"w\") as f:\n",
    "      f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_lr.py\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# training_data_directory for used_cars.csv from local machine\n",
    "training_data_directory = \"../UsedCarsPricePrediction/train\"\n",
    "# validation_data_directory for used_cars.csv from local machine\n",
    "validation_data_directory = \"../UsedCarsPricePrediction/train\"\n",
    "# test_data_directory for used_cars.csv from local machine\n",
    "test_data_directory = \"../UsedCarsPricePrediction/test\"\n",
    "\n",
    "train_features_data = os.path.join(training_data_directory, \"train_features.csv\") # this\n",
    "train_labels_data = os.path.join(training_data_directory, \"train_labels.csv\")\n",
    "\n",
    "val_features_data = os.path.join(validation_data_directory, \"val_features.csv\")\n",
    "val_labels_data = os.path.join(validation_data_directory, \"val_labels.csv\")\n",
    "\n",
    "test_features_data = os.path.join(test_data_directory, \"test_features.csv\")\n",
    "test_labels_data = os.path.join(test_data_directory, \"test_labels.csv\")\n",
    "\n",
    "X_train = pd.read_csv(train_features_data, header=None)\n",
    "y_train = pd.read_csv(train_labels_data, header=None)\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# X_test = pd.read_csv(test_features_data, header=None)\n",
    "X_val = pd.read_csv(val_features_data, header=None)\n",
    "y_val = pd.read_csv(val_labels_data, header=None)\n",
    "\n",
    "y_pred_val = model_lr.predict(X_val)\n",
    "\n",
    "# print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False)};\")\n",
    "print(f\"RMSE: {mean_squared_error(y_val, y_pred_val, squared=False)};\")\n",
    "# print accuracy score on the training and validation sets\n",
    "print(f\"Training Accuracy: {model_lr.score(X_train, y_train)}\")\n",
    "print(f\"Validation Accuracy: {model_lr.score(X_val, y_val)}\")\n",
    "\n",
    "# model_output_directory for used_cars.csv from local machine\n",
    "model_output_directory = os.path.join(\"../UsedCarsPricePrediction/model\", \"model.joblib\")\n",
    "\n",
    "print(f\"Saving model to {model_output_directory}\")\n",
    "joblib.dump(model_lr, model_output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/pre_process.py\n",
    "import os\n",
    "import argparse # \n",
    "import pandas as pd\n",
    "# import azureml.core\n",
    "import numpy as np\n",
    "# import mlflow\n",
    "# import mlflow.sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from azureml.core import Workspace\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    " \n",
    "\n",
    "    # input and output arguments passed by the estimator \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--output\", type=str, help=\"path to output data\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    ###################\n",
    "    #<prepare the data>\n",
    "    ###################\n",
    "    \n",
    "    print(\"input data:\", args.data)\n",
    "    \n",
    "    data = pd.read_csv(args.data)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    #<processing>\n",
    "    ###################\n",
    "\n",
    "    # Separate categorical and numerical features\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Apply label encoding to categorical columns\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "    # Apply data scaling to numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "    # Exporting processed data to local\n",
    "    processed_data_path = os.path.join(args.output, 'used_cars_processed.csv')\n",
    "    data.to_csv(processed_data_path, index=False)\n",
    "    print(\"processed data is exported to\", processed_data_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    " main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to process the data and save the processed data in the train_src_dir directory \n",
    "!python {train_src_dir}/pre_process.py --data {train_src_dir}/used_cars.csv --output {train_src_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_gbr.py\n",
    "\n",
    "# import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
    "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
    "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    df = pd.read_csv(args.data)\n",
    "    \n",
    "    target = 'price'\n",
    "    numeric_features = ['Segment','Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "    categorical_features = []\n",
    "\n",
    "    X = df.drop([target], axis=1)\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # split the training data into train and validation sets \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model_gbr = GradientBoostingRegressor(\n",
    "    n_estimators=args.n_estimators,\n",
    "    learning_rate=args.learning_rate\n",
    "    )\n",
    "\n",
    "    model_pipeline = make_pipeline(model_gbr)\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # print the training accuracy score\n",
    "    print(\"training accuracy score:\", model_pipeline.score(X_train, y_train))\n",
    "\n",
    "    # print the training evaluation metrics\n",
    "    print(\"training R2 score:\", model_pipeline.score(X_train, y_train))\n",
    "    print(\"training MAE:\", mean_absolute_error(y_train, model_pipeline.predict(X_train)))\n",
    "    print(\"training MSE:\", mean_squared_error(y_train, model_pipeline.predict(X_train)))\n",
    "    print(\"training RMSE:\", np.sqrt(mean_squared_error(y_train, model_pipeline.predict(X_train))))\n",
    "\n",
    "    # apply the model to the validation dataset \n",
    "    y_pred = model_pipeline.predict(X_val)\n",
    "\n",
    "    # print validation accuracy and R2 score\n",
    "    print(\"validation accuracy:\", model_pipeline.score(X_val, y_val))\n",
    "\n",
    "    # print the evaluation metrics for the validation dataset \n",
    "    print(\"validation R2 score:\", r2_score(y_val, y_pred))\n",
    "    print(\"validation MAE:\", mean_absolute_error(y_val, y_pred))\n",
    "    print(\"validation MSE:\", mean_squared_error(y_val, y_pred))\n",
    "    print(\"validation RMSE:\", np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "\n",
    "    # build a dataframe with evaluation metrics for training and validation datasets \n",
    "    eval_df = pd.DataFrame(\n",
    "    {\n",
    "    'R2_score_train': [model_pipeline.score(X_train, y_train)],\n",
    "    'R2_score_val': [model_pipeline.score(X_val, y_val)],\n",
    "    'MAE_train': [mean_absolute_error(y_train, model_pipeline.predict(X_train))],\n",
    "    'MAE_val': [mean_absolute_error(y_val, y_pred)],\n",
    "    'MSE_train': [mean_squared_error(y_train, model_pipeline.predict(X_train))],\n",
    "    'MSE_val': [mean_squared_error(y_val, y_pred)],\n",
    "    'RMSE_train': [np.sqrt(mean_squared_error(y_train, model_pipeline.predict(X_train)))],\n",
    "    'RMSE_val': [np.sqrt(mean_squared_error(y_val, y_pred))]\n",
    "    }\n",
    "    )\n",
    "\n",
    "    # save the model to the outputs directory for capture\n",
    "    model_output_path = 'outputs/model_gbr.pkl'\n",
    "    joblib.dump(model_pipeline, model_output_path)\n",
    "    print(\"saved model to\", model_output_path)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory \n",
    "!python {train_src_dir}/model_gbr.py --data {train_src_dir}/used_cars_processed.csv --n_estimators 500 --learning_rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory \n",
    "!python {train_src_dir}/model_gbr.py --data {train_src_dir}/used_cars_processed.csv --n_estimators 100 --learning_rate 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from the outputs directory and test it on the test dataset \n",
    "model_output_path = 'outputs/model_gbr.pkl'\n",
    "model_gbr = joblib.load(model_output_path)\n",
    "\n",
    "# load the test dataset\n",
    "test_data_path = '../UsedCarsPricePrediction/test/used_cars_test.csv'\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "\n",
    "# separate the target variable from the test dataset\n",
    "target = 'price'\n",
    "X_test = df_test.drop([target], axis=1)\n",
    "y_test = df_test[target]\n",
    "\n",
    "# apply the model to the test dataset\n",
    "y_pred = model_gbr.predict(X_test)\n",
    "\n",
    "# print the evaluation metrics for the test dataset\n",
    "print(\"test R2 score:\", model_gbr.score(X_test, y_test))\n",
    "print(\"test MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"test MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"test RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# build a dataframe with evaluation metrics for the test dataset\n",
    "eval_df = pd.DataFrame(\n",
    "{\n",
    "'R2_score_test': [model_gbr.score(X_test, y_test)],\n",
    "'MAE_test': [mean_absolute_error(y_test, y_pred)],\n",
    "'MSE_test': [mean_squared_error(y_test, y_pred)],\n",
    "'RMSE_test': [np.sqrt(mean_squared_error(y_test, y_pred))]\n",
    "}\n",
    ")\n",
    "\n",
    "# print the evaluation dataframe\n",
    "eval_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_lr.py\n",
    "\n",
    "# import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
    "    \n",
    "        args = parser.parse_args()\n",
    "    \n",
    "        df = pd.read_csv(args.data)\n",
    "        \n",
    "        target = 'price'\n",
    "        numeric_features = ['Segment','Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "        categorical_features = []\n",
    "    \n",
    "        X = df.drop([target], axis=1)\n",
    "        y = df[target]\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # split the training data into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "        model_lr = LinearRegression()\n",
    "    \n",
    "        model_pipeline = make_pipeline(model_lr)\n",
    "    \n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "        # print training accuracy and R2 score\n",
    "        print(\"training accuracy:\", model_pipeline.score(X_train, y_train))\n",
    "        print(\"training R2 score:\", model_pipeline.score(X_train, y_train))\n",
    "\n",
    "        # print validation accuracy and R2 score\n",
    "        print(\"validation accuracy:\", model_pipeline.score(X_val, y_val))\n",
    "        print(\"validation R2 score:\", model_pipeline.score(X_val, y_val))\n",
    "        \n",
    "        # print test accuracy and R2 score\n",
    "        print(\"test accuracy:\", model_pipeline.score(X_test, y_test))\n",
    "        print(\"test R2 score:\", model_pipeline.score(X_test, y_test))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory\n",
    "!python {train_src_dir}/model_lr.py --data {train_src_dir}/used_cars_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_dt.py\n",
    "\n",
    "# import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
    "    \n",
    "        args = parser.parse_args()\n",
    "    \n",
    "        df = pd.read_csv(args.data)\n",
    "        \n",
    "        target = 'price'\n",
    "        numeric_features = ['Segment','Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "        categorical_features = []\n",
    "    \n",
    "        X = df.drop([target], axis=1)\n",
    "        y = df[target]\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # split the training data into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "        model_dt = DecisionTreeRegressor()\n",
    "    \n",
    "        model_pipeline = make_pipeline(model_dt)\n",
    "    \n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "        # print training accuracy and R2 score\n",
    "        print(\"training accuracy:\", model_pipeline.score(X_train, y_train))\n",
    "        print(\"training R2 score:\", model_pipeline.score(X_train, y_train))\n",
    "\n",
    "        # print validation accuracy and R2 score\n",
    "        print(\"validation accuracy:\", model_pipeline.score(X_val, y_val))\n",
    "        print(\"validation R2 score:\", model_pipeline.score(X_val, y_val))\n",
    "        \n",
    "        # print test accuracy and R2 score\n",
    "        print(\"test accuracy:\", model_pipeline.score(X_test, y_test))\n",
    "        print(\"test R2 score:\", model_pipeline.score(X_test, y_test))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory\n",
    "!python {train_src_dir}/model_dt.py --data {train_src_dir}/used_cars_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_rf.py\n",
    "\n",
    "# import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
    "    \n",
    "        args = parser.parse_args()\n",
    "    \n",
    "        df = pd.read_csv(args.data)\n",
    "        \n",
    "        target = 'price'\n",
    "        numeric_features = ['Segment','Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "        categorical_features = []\n",
    "    \n",
    "        X = df.drop([target], axis=1)\n",
    "        y = df[target]\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # split the training data into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "        model_rf = RandomForestRegressor()\n",
    "    \n",
    "        model_pipeline = make_pipeline(model_rf)\n",
    "    \n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "        # print training accuracy and R2 score\n",
    "        print(\"training accuracy:\", model_pipeline.score(X_train, y_train))\n",
    "        print(\"training R2 score:\", model_pipeline.score(X_train, y_train))\n",
    "\n",
    "        # print validation accuracy and R2 score\n",
    "        print(\"validation accuracy:\", model_pipeline.score(X_val, y_val))\n",
    "        print(\"validation R2 score:\", model_pipeline.score(X_val, y_val))\n",
    "        \n",
    "        # print test accuracy and R2 score\n",
    "        print(\"test accuracy:\", model_pipeline.score(X_test, y_test))\n",
    "        print(\"test R2 score:\", model_pipeline.score(X_test, y_test))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory\n",
    "!python {train_src_dir}/model_rf.py --data {train_src_dir}/used_cars_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_nn.py\n",
    "\n",
    "# import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
    "    \n",
    "        args = parser.parse_args()\n",
    "    \n",
    "        df = pd.read_csv(args.data)\n",
    "        \n",
    "        target = 'price'\n",
    "        numeric_features = ['Segment','Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "        categorical_features = []\n",
    "    \n",
    "        X = df.drop([target], axis=1)\n",
    "        y = df[target]\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # split the training data into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "        model_nn = MLPRegressor()\n",
    "    \n",
    "        model_pipeline = make_pipeline(model_nn)\n",
    "    \n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "        # print training accuracy and R2 score\n",
    "        print(\"training accuracy:\", model_pipeline.score(X_train, y_train))\n",
    "        print(\"training R2 score:\", model_pipeline.score(X_train, y_train))\n",
    "\n",
    "        # print validation accuracy and R2 score\n",
    "        print(\"validation accuracy:\", model_pipeline.score(X_val, y_val))\n",
    "        print(\"validation R2 score:\", model_pipeline.score(X_val, y_val))\n",
    "        \n",
    "        # print test accuracy and R2 score\n",
    "        print(\"test accuracy:\", model_pipeline.score(X_test, y_test))\n",
    "        print(\"test R2 score:\", model_pipeline.score(X_test, y_test))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory\n",
    "!python {train_src_dir}/model_nn.py --data {train_src_dir}/used_cars_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_svr.py\n",
    "\n",
    "# import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
    "    \n",
    "        args = parser.parse_args()\n",
    "    \n",
    "        df = pd.read_csv(args.data)\n",
    "        \n",
    "        target = 'price'\n",
    "        numeric_features = ['Segment','Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "        categorical_features = []\n",
    "    \n",
    "        X = df.drop([target], axis=1)\n",
    "        y = df[target]\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # split the training data into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "        model_svr = SVR()\n",
    "    \n",
    "        model_pipeline = make_pipeline(model_svr)\n",
    "    \n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "        # print training accuracy and R2 score\n",
    "        print(\"training accuracy:\", model_pipeline.score(X_train, y_train))\n",
    "        print(\"training R2 score:\", model_pipeline.score(X_train, y_train))\n",
    "\n",
    "        # print validation accuracy and R2 score\n",
    "        print(\"validation accuracy:\", model_pipeline.score(X_val, y_val))\n",
    "        print(\"validation R2 score:\", model_pipeline.score(X_val, y_val))\n",
    "        \n",
    "        # print test accuracy and R2 score\n",
    "        print(\"test accuracy:\", model_pipeline.score(X_test, y_test))\n",
    "        print(\"test R2 score:\", model_pipeline.score(X_test, y_test))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory\n",
    "!python {train_src_dir}/model_svr.py --data {train_src_dir}/used_cars_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_knn.py\n",
    "\n",
    "# import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
    "    \n",
    "        args = parser.parse_args()\n",
    "    \n",
    "        df = pd.read_csv(args.data)\n",
    "        \n",
    "        target = 'price'\n",
    "        numeric_features = ['Segment','Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "        categorical_features = []\n",
    "    \n",
    "        X = df.drop([target], axis=1)\n",
    "        y = df[target]\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # split the training data into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "        model_knn = KNeighborsRegressor()\n",
    "    \n",
    "        model_pipeline = make_pipeline(model_knn)\n",
    "    \n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "        # print training accuracy and R2 score\n",
    "        print(\"training accuracy:\", model_pipeline.score(X_train, y_train))\n",
    "        print(\"training R2 score:\", model_pipeline.score(X_train, y_train))\n",
    "\n",
    "        # print validation accuracy and R2 score\n",
    "        print(\"validation accuracy:\", model_pipeline.score(X_val, y_val))\n",
    "        print(\"validation R2 score:\", model_pipeline.score(X_val, y_val))\n",
    "        \n",
    "        # print test accuracy and R2 score\n",
    "        print(\"test accuracy:\", model_pipeline.score(X_test, y_test))\n",
    "        print(\"test R2 score:\", model_pipeline.score(X_test, y_test))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory\n",
    "!python {train_src_dir}/model_knn.py --data {train_src_dir}/used_cars_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/model_bayesian.py\n",
    "\n",
    "# import mlflow\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# mlflow.start_run()\n",
    "\n",
    "def main():\n",
    "    \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
    "    \n",
    "        args = parser.parse_args()\n",
    "    \n",
    "        df = pd.read_csv(args.data)\n",
    "        \n",
    "        target = 'price'\n",
    "        numeric_features = ['Segment','Kilometers_Driven', 'Mileage', 'Engine','Power','Seats']\n",
    "        categorical_features = []\n",
    "    \n",
    "        X = df.drop([target], axis=1)\n",
    "        y = df[target]\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # split the training data into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "        model_bayesian = BayesianRidge()\n",
    "    \n",
    "        model_pipeline = make_pipeline(model_bayesian)\n",
    "    \n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "        # print training accuracy and R2 score\n",
    "        print(\"training accuracy:\", model_pipeline.score(X_train, y_train))\n",
    "        print(\"training R2 score:\", model_pipeline.score(X_train, y_train))\n",
    "\n",
    "        # print validation accuracy and R2 score\n",
    "        print(\"validation accuracy:\", model_pipeline.score(X_val, y_val))\n",
    "        print(\"validation R2 score:\", model_pipeline.score(X_val, y_val))\n",
    "        \n",
    "        # print test accuracy and R2 score\n",
    "        print(\"test accuracy:\", model_pipeline.score(X_test, y_test))\n",
    "        print(\"test R2 score:\", model_pipeline.score(X_test, y_test))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model and save the model in the train_src_dir directory\n",
    "!python {train_src_dir}/model_bayesian.py --data {train_src_dir}/used_cars_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# different regression models \n",
    "# 1. Linear Regression\n",
    "# 2. Decision Tree Regression\n",
    "# 3. Random Forest Regression\n",
    "# 4. Gradient Boosting Regression\n",
    "# 5. Neural Network Regression\n",
    "# 6. Support Vector Regression\n",
    "# 7. K-Nearest Neighbors Regression\n",
    "# 8. Ridge Regression\n",
    "# 9. Lasso Regression\n",
    "# 10. ElasticNet Regression\n",
    "# 11. Bayesian Regression\n",
    "# 12. Huber Regression\n",
    "# 13. TheilSen Regression\n",
    "# 14. RANSAC Regression\n",
    "# 15. Poisson Regression\n",
    "# 16. Gamma Regression\n",
    "# 17. Tweedie Regression\n",
    "# 18. Passive Aggressive Regression\n",
    "# 19. Orthogonal Matching Pursuit Regression\n",
    "# 20. Bayesian Ridge Regression\n",
    "# 21. ARD Regression\n",
    "# 22. SGD Regression\n",
    "# 23. Extra Trees Regression\n",
    "# 24. Multi Task ElasticNet Regression\n",
    "# 25. Multi Task Lasso Regression\n",
    "# 26. Multi Task LassoCV Regression\n",
    "# 27. Multi Task Ridge Regression\n",
    "# 28. Radius Neighbors Regression\n",
    "# 29. Isotonic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script to train the model using different values of n_estimators and learning_rate using for loop \n",
    "for n_estimators in [100, 200, 300]:\n",
    "    for learning_rate in [0.1, 0.01, 0.001]:\n",
    "        !python {train_src_dir}/main.py --data {train_src_dir}/used_cars_processed.csv --n_estimators {n_estimators} --learning_rate {learning_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/pre_process.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "def main():\n",
    " \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    data = pd.read_csv(args.data)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    #<processing>\n",
    "    ###################\n",
    "\n",
    "    # Separate categorical and numerical features\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Apply label encoding to categorical columns\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "    # Apply data scaling to numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "    # Exporting processed data to local\n",
    "    data.to_csv(os.path.join(args.output, 'processed_data.csv'), index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
